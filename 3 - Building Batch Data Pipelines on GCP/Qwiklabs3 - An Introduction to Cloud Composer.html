<!DOCTYPE html>
<html lang='en'>
<head>
<meta content='[]' name='active-experiments'>
<meta content='{&quot;userId&quot;:2485272}' name='help-api-product-data'>
<meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="ZqiwVvKWBL36fhHPbveymw6qRp2kRenDv+XUOshlWxuZYs6F5y8NQ+jgi7+XjQF3B1mAFBZKxXWFQeghIiBzxw==" />
<title>An Introduction to Cloud Composer | Qwiklabs</title>
<meta content='width=device-width, initial-scale=1.0, maximum-scale=1, user-scalable=0' name='viewport'>
<meta content='In this lab, you create a Cloud Composer environment using the GCP Console. You then use the Airflow web interface to run a workflow that verifies a data file, creates and runs an Apache Hadoop wordcount job on a Dataproc cluster, and deletes the cluster.' name='description'>
<meta content='Qwiklabs' name='author'>
<meta content='1rRsY0INj8RvwB5EF5pwdxt2A2P9aDgAlsICaJ0d5w0' name='google-site-verification'>
<meta content='An Introduction to Cloud Composer | Qwiklabs' property='og:title'>
<meta content='website' property='og:type'>
<meta content='/favicon-144.png' property='og:image'>
<meta content='Qwiklabs' property='og:site_name'>
<meta content='In this lab, you create a Cloud Composer environment using the GCP Console. You then use the Airflow web interface to run a workflow that verifies a data file, creates and runs an Apache Hadoop wordcount job on a Dataproc cluster, and deletes the cluster.' property='og:description'>
<meta content='/qwiklabs_logo_900x887.png' property='og:logo' size='900x887'>
<meta content='/qwiklabs_logo_994x187.png' property='og:logo' size='994x187'>
<meta content='#3681E4' property='msapplication-TileColor'>
<meta content='/favicon-144.png' property='msapplication-TileImage'>
<link href='/favicon-32.png' rel='shortcut icon'>
<link color='#3681E4' href='/favicon-svg.svg' rel='mask-icon'>
<link href='/favicon-180.png' rel='apple-touch-icon-precomposed'>
<link rel="stylesheet" media="screen" href="https://fonts.googleapis.com/css?family=Oswald:400|Roboto+Mono:400,700|Roboto:300,400,500,700|Google+Sans:300,400,500,700|Google+Sans+Display:400|Material+Icons|Google+Material+Icons" />


<!--[if lt IE 9]>
<script src='http://html5shim.googlecode.com/svn/trunk/html5.js' type='text/javascript'></script>
<![endif]-->
<!--[endif]>  <![endif]-->
<script>
//<![CDATA[
window.gon={};gon.current_user={"firstname":"Carlo","lastname":"Andr\u00e9 Castro Galindo","fullname":"Carlo Andr\u00e9 Castro Galindo","company":"Coursera","email":"carlocastrogalindo@gmail.com","origin":"googlecoursera-run, lti-coursera","subscriptions":0,"id":"eb3f0602d940d94d2eaeef36f2aa2e77","qlCreatedAt":"2020-02-28 17:36:48 UTC","optIn":null};gon.segment="j4Im8pqIko0Lxq4wVVZWMPMM0EroHUvb";gon.deployment="googlecoursera-run";
//]]>
</script>
<script src='https://www.google.com/recaptcha/api.js?render=6LeVI8IUAAAAAJNdox5eTkYrw9SbvhZ1TFyv3iHr'></script>
<script type='application/ld+json'>
{
  "@context": "http://schema.org",
  "@type": "WebSite",
  "url": "https://www.qwiklabs.com/",
  "potentialAction": {
    "@type": "SearchAction",
    "target": "https://www.qwiklabs.com/catalog?keywords={search_term_string}",
    "query-input": "required name=search_term_string"
  }
}
</script>
<script id='ze-snippet' src='https://static.zdassets.com/ekr/snippet.js?key=511e4158-0aec-4e3c-b2e6-4daa1769f51e'></script>



<link rel="stylesheet" media="all" href="https://cdn.qwiklabs.com/assets/application-0fbb2e2ec51da40239f1b54d7bd34aa50f59bc233036120124c2fb4e6c5fd90e.css" />
<script>
  EVENT_SOURCE_BASE_URL = "https://googlecoursera-run.qwiklabs.com/nchan-sub?id=";
</script>
<script src="https://cdn.qwiklabs.com/polyfills/webcomponents-loader.js"></script>
<script src="https://cdn.qwiklabs.com/assets/hallofmirrors/hallofmirrors-c8a543a8e9e63ffd57a2b2bb36bd5c342eaa604dffa0f1c63a43d84ccebe2d76.js"></script>
<script src="https://www.youtube.com/iframe_api"></script>
<script src="https://cdn.qwiklabs.com/assets/vendor-45d462772c30000424907184f70c7157e95fb6227698d1671c5051818a6f60d8.js"></script>
<script src="https://cdn.qwiklabs.com/assets/application-3fc70562de25b3405b5605bd7e10c53474b5c01cb26ae806a9f1c321050f4a1d.js"></script>
</head>
<body class='focuses focuses-show lab-show l-full no-nav'>
<div class='header-container'>
<div class='header'>
<a class='mdl-button mdl-button--icon mdl-js-button mdl-js-ripple-effect header__button header__button--nav header__nav-panel-button js-nav-toggle'>
<i class='material-icons'>menu</i>
</a>
<div class='header__title'>
<a class="mdl-button mdl-js-button mdl-button--icon mdl-js-ripple-effect header__button header__button--nav" href="https://www.coursera.org/"><ql-icon>arrow_back</ql-icon></a>

<h1 class='headline-5'>
An Introduction to Cloud Composer
</h1>
</div>
<div class='header__actions'>
<a class='mdl-button mdl-js-button mdl-button--icon mdl-js-ripple-effect header__button header__button--action header__button--search js-header-search-bar-button'>
<i class='material-icons'>search</i>
</a>
<a class="mdl-button mdl-button--icon mdl-js-button mdl-js-ripple-effect" id="toggle-lab-control-panel" href="javascript:;"><i class='material-icons'>description</i>
</a><div class='mdl-tooltip js-tooltip' data-mdl-for='toggle-lab-control-panel'>
Toggle Lab Panel
</div>

<ql-help context="lab" productdata="{&quot;userId&quot;:2485272}" data-analytics-action="opened_help" data-analytics-label="lab"></ql-help>
<a class='header-my-account-button mdl-button mdl-button--icon mdl-js-button mdl-js-ripple-effect js-my-account-button'>
<img class="avatar " alt="avatar image" src="https://secure.gravatar.com/avatar/be719396bbcc1e8bcb204a54e1920c54.png?s=80&amp;d=mm" />
</a>
<div class='header-my-account-menu js-my-account-menu'>
<div class='card elevation-2 no-padding'>
<div class='my-account-menu__top'>
<img class="avatar " alt="avatar image" src="https://secure.gravatar.com/avatar/be719396bbcc1e8bcb204a54e1920c54.png?s=80&amp;d=mm" />
<div class='my-account-menu__info'>
<h4 class='subtitle-headline-1'>
Carlo André Castro Galindo
</h4>
<p class='body-2 text--gray'>
<span>carlocastrogalindo@gmail.com</span>
</p>
<a class="button" href="/my_account/profile">My Account</a>
</div>
</div>
<div class='my-account-menu__bottom'>
<a class="text--green subtitle-headline-2" href="/my_account/credits">0 Credits
</a><a data-analytics-action="clicked_sign_out" class="button button--hairline" rel="nofollow" data-method="delete" href="/users/sign_out">Sign Out</a>
</div>
</div>
</div>

</div>
</div>
<div class='header__search-bar js-header-search-bar'>
<form id="catalog-search-mobile" onsubmit="ql.catalogSearchFilter(); return false;" action="/searches/elasticsearch" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="6zwZXltv0gXbpj8kPoioo2VWzDjeG965Wldo4svIV9IU9meNTtbb+8k4pVTH8htPbKUKsWwU8g9g81T5IY1/Dg==" />
<input type="text" name="keywords" id="keywords" placeholder="Search" maxlength="255" aria-label="catalog search bar" />
</form>

<a class='mdl-button mdl-js-button mdl-button--icon mdl-js-ripple-effect header__button'>
<i class='material-icons'>close</i>
</a>
</div>
</div>

<nav class='nav-bar'>
<a class="nav-bar__item js-navigation-button" href="/"><ql-icon class='nav-bar__item__icon'>
home
</ql-icon>
<span class='nav-bar__item__label'>
Home
</span>
</a>
<a class="nav-bar__item js-navigation-button" href="/catalog"><ql-icon class='nav-bar__item__icon'>
school
</ql-icon>
<span class='nav-bar__item__label'>
Catalog
</span>
</a>
<a class="nav-bar__item js-navigation-button" href="/my_learning"><ql-icon class='nav-bar__item__icon'>
event_note
</ql-icon>
<span class='nav-bar__item__label'>
My Learning
</span>
</a>
</nav>

<nav class='nav-panel js-nav-panel'>
<div class='nav-panel__logo'>
<div class='logo logo--blue'></div>
</div>
<a title="Home" tabindex="-1" class="nav-panel__item js-navigation-button" href="/"><ql-icon class='nav-panel__item__icon'>
home
</ql-icon>
<div class='nav-panel__item__label'>
Home
</div>
</a>
<a title="Catalog" tabindex="-1" class="nav-panel__item js-navigation-button" href="/catalog"><ql-icon class='nav-panel__item__icon'>
school
</ql-icon>
<div class='nav-panel__item__label'>
Catalog
</div>
</a>
<a title="My Learning" tabindex="-1" class="nav-panel__item js-navigation-button" href="/my_learning"><ql-icon class='nav-panel__item__icon'>
event_note
</ql-icon>
<div class='nav-panel__item__label'>
My Learning
</div>
</a>
<div class='nav-panel__spacer'></div>
<a title="Profile" tabindex="-1" class="nav-panel__item js-navigation-button" href="/my_account/profile"><ql-icon class='nav-panel__item__icon'>
account_circle
</ql-icon>
<div class='nav-panel__item__label'>
Profile
</div>
</a>
<a title="Credits &amp; Subscriptions" tabindex="-1" class="nav-panel__item js-navigation-button" href="/my_account/credits"><ql-icon class='nav-panel__item__icon'>
money
</ql-icon>
<div class='nav-panel__item__label'>
Credits &amp; Subscriptions
</div>
</a>
<a title="Security" tabindex="-1" class="nav-panel__item js-navigation-button" href="/my_account/security"><ql-icon class='nav-panel__item__icon'>
security
</ql-icon>
<div class='nav-panel__item__label'>
Security
</div>
</a>
<div class='nav-panel__spacer'></div>
<a class="nav-panel__item" tabindex="-1" href="#"><ql-help>
<div class='nav-panel__help-item'>
<ql-icon class='nav-panel__item__icon'>help</ql-icon>
<div class='nav-panel__item__label'>Help</div>
</div>
</ql-help>
</a><div class='nav-panel__small-links'>
<a tabindex="-1" href="/privacy_policy">Privacy</a>
<a tabindex="-1" href="/terms_of_service">Terms</a>
</div>
</nav>
<div class='nav-panel__overlay js-nav-toggle'></div>

<main class='js-main'>
<span class='hidden' id='flash-sibling-before'></span>

<div class='l-main-wrapper' id='main-wrapper'>







<div class='js-lab-state' data-analytics-payload='{&quot;label&quot;:&quot;An Introduction to Cloud Composer&quot;,&quot;lab_name&quot;:&quot;An Introduction to Cloud Composer&quot;,&quot;classroom_name&quot;:null,&quot;deployment&quot;:&quot;googlecoursera-run&quot;}' data-focus-id='46741' data-lab-billing-limit='0.0' data-lab-duration='5400' data-parent='classroom'></div>
<ql-lab-control-panel class='js-lab-control-panel l-lab-control-panel' connectionDetails='[]' connectionFiles='[]' labControlButton='{&quot;disabled&quot;:false,&quot;pending&quot;:false,&quot;running&quot;:false}' labTimer='{&quot;ticking&quot;:false,&quot;secondsRemaining&quot;:5400}' studentResources='[{&quot;text&quot;:&quot;Flexible, Easy Data Pipelines on Google Cloud with Cloud Compooser (NEXT&#39;18)&quot;,&quot;icon&quot;:&quot;videocam&quot;,&quot;href&quot;:&quot;https://www.youtube.com/watch?v=GeNFEtt-D4k&quot;}]'></ql-lab-control-panel>
<div class='l-lab-main-body'>
<div class='js-lab-content lab-content'>
<div class='alert alert--fake js-alert'>
<p class='alert__message js-alert-message'></p>
<a class='alert__close js-alert-close'>
<i class='fa fa-times'></i>
</a>
<iframe class='l-ie-iframe-fix'></iframe>
</div>
<div class='lab-content__markdown-wrapper'>
<div class='lab-preamble'>
<h1 class='lab-preamble__title'>
An Introduction to Cloud Composer
</h1>
<div class='lab-preamble__details subtitle-headline-1'>
<span>1 hour 30 minutes</span>
<span>1 Credit</span>
<div class='lab__rating'>
<a href="/focuses/46741/reviews?parent=catalog"><div class='rateit' data-rateit-readonly='true' data-rateit-value='4.0083'></div>

</a><a data-target='#lab-review-modal' data-toggle='modal'>
Rate Lab
</a>
</div>
</div>
</div>

<div class='lab-content__inner-wrapper'>
<div class='js-markdown-instructions lab-content__markdown markdown-lab-instructions' id='markdown-lab-instructions'>



<h2 id="step1">Overview</h2>
<p>Workflows are a common theme in data analytics - they involve ingesting, transforming, and analyzing data to figure out the meaningful information within. In Google Cloud Platform (GCP), the tool for hosting workflows is Cloud Composer which is a hosted version of the popular open source workflow tool Apache Airflow.</p>
<p>In this lab, you use the GCP Console to set up a Cloud Composer environment. You then use Cloud Composer to go through a simple workflow that verifies the existence of a data file, creates a Cloud Dataproc cluster, runs an Apache Hadoop wordcount job on the Cloud Dataproc cluster, and deletes the Cloud Dataproc cluster afterwards.</p>
<h3>What you'll do</h3>
<ul>
<li>
<p>Use GCP Console to create the Cloud Composer environment</p>
</li>
<li>
<p>View and run the DAG (Directed Acyclic Graph) in the Airflow web interface</p>
</li>
<li>
<p>View the results of the wordcount job in storage.</p>
</li>
</ul>
<h2 id="step2">Setup and requirements</h2>
<h3>Qwiklabs setup</h3>
<h4>What you'll need</h4>
<p>To complete this lab, you’ll need:</p>
<ul>
<li>
<p>Access to a standard internet browser (Chrome browser recommended).</p>
</li>
<li>
<p>Time. Note the lab’s <strong>Completion</strong> time in Qwiklabs. This is an estimate of the time it should take to complete all steps.  Plan your schedule so you have time to complete the lab. Once you start the lab, you will not be able to pause and return later (you begin at step 1 every time you start a lab).</p>
</li>
<li>
<p>The lab's <strong>Access</strong> time is how long your lab resources will be available. If you finish your lab with access time still available, you will be able to explore the Google Cloud Platform or work on any section of the lab that was marked "if you have time". Once the Access time runs out, your lab will end and all resources will terminate.</p>
</li>
<li>
<p>You <strong>DO NOT</strong> need a Google Cloud Platform account or project. An account, project and associated resources are provided to you as part of this lab.</p>
</li>
<li>
<p>If you already have your own GCP account, make sure you do not use it for this lab.</p>
</li>
<li>
<p>If your lab prompts you to log into the console, <strong>use only the student account provided to you by the lab</strong>. This prevents you from incurring charges for lab activities in your personal GCP account.</p>
</li>
</ul>
<h4>Start your lab</h4>
<p>When you are ready, click <strong>Start Lab</strong>. You can track your lab’s progress with the status bar at the top of your screen.</p>
<aside>
<strong>Important</strong> What is happening during this time?
  Your lab is spinning up GCP resources for you behind the scenes, including an account, a project, resources within the project, and permission for you to control the resources needed to run the lab. This means that instead of spending time manually setting up a project and building resources from scratch as part of your lab, you can begin learning more quickly.

</aside>
<h4>Find Your Lab’s GCP Username and Password</h4>
<p>To access the resources and console for this lab, locate the Connection Details panel in Qwiklabs.  Here you will find the account ID and password for the account you will use to log in to the Google Cloud Platform:</p>
<p><img alt="Open Google Console" src="https://cdn.qwiklabs.com/0d78dhX6IVMVWmixCPPSBbmi5O2GPokCXf1Ps1AkTgI%3D"></p>
<p>If your lab provides other resource identifiers or connection-related information, it will appear on this panel as well.</p>

<h3>Google Cloud Platform Console</h3>
<h4>Log in to Google Cloud Console</h4>
<p>Using the Qwiklabs browser tab/window or the separate browser you are using for the Qwiklabs session, copy the Username from the Connection Details panel and click the <strong>Open Google Console</strong> button.</p>
<p>You'll be asked to Choose an account. Click <strong>Use another account</strong>.
<img alt="Google_choose_Account" src="https://cdn.qwiklabs.com/wNoohdL%2BwyBavWAhxkN5euPH2ulJhiOzoBlmi1%2BmGSw%3D"></p>
<p>Paste in the Username, and then the Password as prompted:</p>
<p><img alt="Sign in to continue to Google Cloud Platform" src="https://cdn.qwiklabs.com/rP81bHN99Vr7kaKU7fqy2IuSj1rjjNXkD1iunRSBWBw%3D"></p>
<p>Accept the terms and conditions.</p>
<p>Since this is a temporary account, which you will only have to access for this one lab:</p>
<ul>
<li>Do not add recovery options</li>
<li>Do not sign up for free trials</li>
</ul>
<aside>
<strong>Note:</strong> You can view the list of services by clicking the GCP Navigation menu button at the top-left next to “Google Cloud Platform”.

  <img alt="Cloud Console Menu" src="https://cdn.qwiklabs.com/RIuVVYUkGtVaWhxtIFJugxyy%2FORWQYw7OrLR0bJlReI%3D">
</aside>

<h3>Activate Google Cloud Shell</h3>
<p>Google Cloud Shell is a virtual machine that is loaded with development tools. It offers a persistent 5GB home directory and runs on the Google Cloud.
Google Cloud Shell provides command-line access to your GCP resources.</p>
<ol>
<li>
<p>In GCP console, on the top right toolbar, click the Open Cloud Shell button.</p>
<p><img alt="Cloud Shell icon" src="https://cdn.qwiklabs.com/vdY5e%2Fan9ZGXw5a%2FZMb1agpXhRGozsOadHURcR8thAQ%3D"></p>
</li>
<li>
<p>Click <strong>Continue</strong>.
<img alt="cloudshell_continue.png" src="https://cdn.qwiklabs.com/lr3PBRjWIrJ%2BMQnE8kCkOnRQQVgJnWSg4UWk16f0s%2FA%3D"></p>
</li>
</ol>
<p>It takes a few moments to provision and connect to the environment. When you are connected, you are already authenticated, and the project is set to your <em>PROJECT_ID</em>. For example:</p>
<p><img alt="Cloud Shell Terminal" src="https://cdn.qwiklabs.com/hmMK0W41Txk%2B20bQyuDP9g60vCdBajIS%2B52iI2f4bYk%3D"></p>
<p><strong>gcloud</strong> is the command-line tool for Google Cloud Platform. It comes pre-installed on Cloud Shell and supports tab-completion.</p>
<p>You can list the active account name with this command:</p>
<pre><code>gcloud auth list&#x000A;</code></pre>
<p>Output:</p>
<pre><code class="language-output prettyprint">Credentialed accounts:&#x000A; - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active)&#x000A;</code></pre>
<p>Example output:</p>
<pre><code class="language-Output prettyprint">Credentialed accounts:&#x000A; - google1623327_student@qwiklabs.net&#x000A;</code></pre>
<p>You can list the project ID with this command:</p>
<pre><code>gcloud config list project&#x000A;</code></pre>
<p>Output:</p>
<pre><code class="language-output prettyprint">[core]&#x000A;project = &lt;project_ID&gt;&#x000A;</code></pre>
<p>Example output:</p>
<pre><code class="language-Output prettyprint">[core]&#x000A;project = qwiklabs-gcp-44776a13dea667a6&#x000A;</code></pre>
<ql-infobox>
  Full documentation of <strong>gcloud</strong> is available on <a href="https://cloud.google.com/sdk/gcloud">Google Cloud gcloud Overview</a>.
</ql-infobox>

<h2 id="step3">Create Cloud Composer environment</h2>
<p>In this section, you create a Cloud Composer environment.</p>
<ol>
<li>Go to <strong>Navigation menu</strong> &gt; <strong>Composer</strong>:</li>
</ol>
<p><img alt="6d5cc1e126272384.png" src="https://cdn.qwiklabs.com/iOc8p24o0BgBX3dhW84X37YNt7e9t0BhcAq2y4IXgfI%3D"></p>
<ol start="2">
<li>Click <strong>CREATE ENVIRONMENT</strong> and set the following for your environment:</li>
</ol>
<table>

<tr>
<th><strong>Property</strong></th>
<th><strong>Value</strong></th>
</tr>


<tr>
<td><strong>Name</strong></td>
<td><code>highcpu</code></td>
</tr>
<tr>
<td><strong>Location</strong></td>
<td><code>us-central1</code></td>
</tr>
<tr>
<td><strong>Zone</strong></td>
<td><code>us-central1-a</code></td>
</tr>
<tr>
<td><strong>Machine type</strong></td>
<td>n1-highcpu-4</td>
</tr>

</table>
<p>Leave all other settings as default.</p>
<ol start="3">
<li>Click <strong>Create</strong>.</li>
</ol>
<p>The environment creation process is completed when the green checkmark displays to the left of the environment name on the Environments page in the GCP Console.</p>
<p>It can take 10-15 minutes for the environment to complete the setup process. Continue with the lab while the environment spins up.</p>
<p>Click <strong>Check my progress</strong> to verify the objective.</p>
<ql-activity-tracking step="1">
    Create Cloud Composer environment.
</ql-activity-tracking>
<h3>Create a Cloud Storage bucket</h3>
<p>Create a Cloud Storage bucket in your project. This buckets will be used as output for the Hadoop job from Dataproc.</p>
<ol>
<li>
<p>Go to <strong>Navigation menu</strong> &gt; <strong>Storage</strong> &gt; <strong>Browser</strong> and then click <strong>Create bucket</strong>.</p>
</li>
<li>
<p>Give your bucket a universally unique name, then click <strong>Create</strong>.</p>
</li>
</ol>
<p>Remember the Cloud Storage bucket name as you'll use it as an Airflow variable later in the lab.</p>
<p>Click <strong>Check my progress</strong> to verify the objective.</p>
<ql-activity-tracking step="2">
    Create a Cloud Storage bucket.
</ql-activity-tracking>
<h2 id="step4">Airflow and core concepts</h2>
<p>While waiting for your Composer environment to get created, review some terms that are used with Airflow.</p>
<p><a href="https://airflow.apache.org/">Airflow</a> is a platform to programmatically author, schedule and monitor workflows.</p>
<p>Use Airflow to author workflows as directed acyclic graphs (DAGs) of tasks. The airflow scheduler executes your tasks on an array of workers while following the specified dependencies.</p>
<h3>Core concepts</h3>
<p><a href="https://airflow.apache.org/concepts.html#dags">DAG</a></p>
<p>A Directed Acyclic Graph is a collection of all the tasks you want to run, organized in a way that reflects their relationships and dependencies.</p>
<p><a href="https://airflow.apache.org/concepts.html#operators">Operator</a></p>
<p>The description of a single task, it is usually atomic. For example, the <em>BashOperator</em> is used to execute bash command.</p>
<p><a href="https://airflow.apache.org/concepts.html#tasks">Task</a></p>
<p>A parameterised instance of an Operator;  a node in the DAG.</p>
<p><a href="https://airflow.apache.org/concepts.html#task-instances">Task Instance</a></p>
<p>A specific run of a task; characterized as: a DAG, a Task, and a point in time. It has an indicative state: <em>running</em>, <em>success</em>, <em>failed</em>, <em>skipped</em>, ...</p>
<p>You can read more about the concepts  <a href="https://airflow.apache.org/concepts.html#">here</a>.</p>
<h2 id="step5">Defining the workflow</h2>
<p>Now let's discuss the workflow you'll be using. Cloud Composer workflows are comprised of  <a href="https://airflow.incubator.apache.org/concepts.html#dags">DAGs (Directed Acyclic Graphs)</a>. DAGs are defined in standard Python files that are placed in Airflow's <code>DAG_FOLDER</code>. Airflow will execute the code in each file to dynamically build the <code>DAG</code> objects. You can have as many DAGs as you want, each describing an arbitrary number of tasks. In general, each one should correspond to a single logical workflow.</p>
<p>Below is the <code>hadoop_tutorial.py</code> workflow code, also referred to as the DAG:</p>
<pre><code>"""Example Airflow DAG that creates a Cloud Dataproc cluster, runs the Hadoop&#x000A;wordcount example, and deletes the cluster.&#x000A;&#x000A;This DAG relies on three Airflow variables&#x000A;https://airflow.apache.org/concepts.html#variables&#x000A;* gcp_project - Google Cloud Project to use for the Cloud Dataproc cluster.&#x000A;* gce_zone - Google Compute Engine zone where Cloud Dataproc cluster should be&#x000A;  created.&#x000A;* gcs_bucket - Google Cloud Storage bucket to used as output for the Hadoop jobs from Dataproc.&#x000A;  See https://cloud.google.com/storage/docs/creating-buckets for creating a&#x000A;  bucket.&#x000A;"""&#x000A;&#x000A;import datetime&#x000A;import os&#x000A;&#x000A;from airflow import models&#x000A;from airflow.contrib.operators import dataproc_operator&#x000A;from airflow.utils import trigger_rule&#x000A;&#x000A;# Output file for Cloud Dataproc job.&#x000A;output_file = os.path.join(&#x000A;    models.Variable.get('gcs_bucket'), 'wordcount',&#x000A;    datetime.datetime.now().strftime('%Y%m%d-%H%M%S')) + os.sep&#x000A;# Path to Hadoop wordcount example available on every Dataproc cluster.&#x000A;WORDCOUNT_JAR = (&#x000A;    'file:///usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'&#x000A;)&#x000A;# Arguments to pass to Cloud Dataproc job.&#x000A;wordcount_args = ['wordcount', 'gs://pub/shakespeare/rose.txt', output_file]&#x000A;&#x000A;yesterday = datetime.datetime.combine(&#x000A;    datetime.datetime.today() - datetime.timedelta(1),&#x000A;    datetime.datetime.min.time())&#x000A;&#x000A;default_dag_args = {&#x000A;    # Setting start date as yesterday starts the DAG immediately when it is&#x000A;    # detected in the Cloud Storage bucket.&#x000A;    'start_date': yesterday,&#x000A;    # To email on failure or retry set 'email' arg to your email and enable&#x000A;    # emailing here.&#x000A;    'email_on_failure': False,&#x000A;    'email_on_retry': False,&#x000A;    # If a task fails, retry it once after waiting at least 5 minutes&#x000A;    'retries': 1,&#x000A;    'retry_delay': datetime.timedelta(minutes=5),&#x000A;    'project_id': models.Variable.get('gcp_project')&#x000A;}&#x000A;&#x000A;with models.DAG(&#x000A;        'composer_sample_quickstart',&#x000A;        # Continue to run DAG once per day&#x000A;        schedule_interval=datetime.timedelta(days=1),&#x000A;        default_args=default_dag_args) as dag:&#x000A;&#x000A;    # Create a Cloud Dataproc cluster.&#x000A;    create_dataproc_cluster = dataproc_operator.DataprocClusterCreateOperator(&#x000A;        task_id='create_dataproc_cluster',&#x000A;        # Give the cluster a unique name by appending the date scheduled.&#x000A;        # See https://airflow.apache.org/code.html#default-variables&#x000A;        cluster_name='quickstart-cluster-{{ ds_nodash }}',&#x000A;        num_workers=2,&#x000A;        zone=models.Variable.get('gce_zone'),&#x000A;        master_machine_type='n1-standard-1',&#x000A;        worker_machine_type='n1-standard-1')&#x000A;&#x000A;    # Run the Hadoop wordcount example installed on the Cloud Dataproc cluster&#x000A;    # master node.&#x000A;    run_dataproc_hadoop = dataproc_operator.DataProcHadoopOperator(&#x000A;        task_id='run_dataproc_hadoop',&#x000A;        main_jar=WORDCOUNT_JAR,&#x000A;        cluster_name='quickstart-cluster-{{ ds_nodash }}',&#x000A;        arguments=wordcount_args)&#x000A;&#x000A;    # Delete Cloud Dataproc cluster.&#x000A;    delete_dataproc_cluster = dataproc_operator.DataprocClusterDeleteOperator(&#x000A;        task_id='delete_dataproc_cluster',&#x000A;        cluster_name='quickstart-cluster-{{ ds_nodash }}',&#x000A;        # Setting trigger_rule to ALL_DONE causes the cluster to be deleted&#x000A;        # even if the Dataproc job fails.&#x000A;        trigger_rule=trigger_rule.TriggerRule.ALL_DONE)&#x000A;&#x000A;    # Define DAG dependencies.&#x000A;    create_dataproc_cluster &gt;&gt; run_dataproc_hadoop &gt;&gt; delete_dataproc_cluster&#x000A;</code></pre>
<p>To orchestrate the three workflow tasks, the DAG imports the following operators:</p>
<ol>
<li>
<code>DataprocClusterCreateOperator</code>: Creates a Cloud Dataproc cluster.</li>
<li>
<code>DataProcHadoopOperator</code>: Submits a Hadoop wordcount job and writes results to a Cloud Storage bucket.</li>
<li>
<code>DataprocClusterDeleteOperator</code>: Deletes the cluster to avoid incurring ongoing Compute Engine charges.</li>
</ol>
<p>The tasks run sequentially, which you can see in this section of the file:</p>
<pre><code># Define DAG dependencies.&#x000A;create_dataproc_cluster &gt;&gt; run_dataproc_hadoop &gt;&gt; delete_dataproc_cluster&#x000A;</code></pre>
<p>The name of the DAG is <code>quickstart</code>, and the DAG runs once each day.</p>
<pre><code>with models.DAG(&#x000A;        'composer_sample_quickstart',&#x000A;        # Continue to run DAG once per day&#x000A;        schedule_interval=datetime.timedelta(days=1),&#x000A;        default_args=default_dag_args) as dag:&#x000A;</code></pre>
<p>Because the <code>start_date</code> that is passed in to <code>default_dag_args</code> is set to <code>yesterday</code>, Cloud Composer schedules the workflow to start immediately after the DAG uploads.</p>
<h2 id="step6">Viewing environment information</h2>
<ol>
<li>
<p>Go back to <strong>Composer</strong> to check on the status of your environment.</p>
</li>
<li>
<p>Once your environment has been created, click the name of the environment (highcpu) to see its details.</p>
</li>
</ol>
<p>On the <strong>Environment details</strong> you'll see information such as the Airflow web interface URL, Kubernetes Engine cluster ID, and a link to the DAGs folder, which is stored in your bucket.</p>
<ql-infobox><strong>Note:</strong> Cloud Composer only schedules the workflows in the <code>/dags</code> folder.</ql-infobox>
<h2 id="step7">Using the Airflow UI</h2>
<p>To access the Airflow web interface using the GCP Console:</p>
<ol>
<li>
<p>Go back to the <strong>Environments</strong> page.</p>
</li>
<li>
<p>In the <strong>Airflow webserver</strong> column for the environment, click <strong>Airflow</strong>.</p>
</li>
<li>
<p>Click on your lab credentials.</p>
</li>
<li>
<p>The Airflow web interface opens in a new browser window.</p>
</li>
</ol>
<h2 id="step8">Setting Airflow variables</h2>
<p>Airflow variables are an Airflow-specific concept that is distinct from <a href="https://cloud.google.com/composer/docs/how-to/managing/environment-variables">environment variables</a>.</p>
<ol>
<li>Select <strong>Admin</strong> &gt; <strong>Variables</strong> from the Airflow menu bar, then <strong>Create</strong>.</li>
</ol>
<p><img alt="4a38ba78af97a898.png" src="https://cdn.qwiklabs.com/O8uLOjzf0%2BIexBYTTlXK1SeU%2BX2yEiX02jjOzwRSx9s%3D"></p>
<ol start="2">
<li>Create the following Aireflow variables, <code>gcp_project</code>, <code>gcs_bucket</code>, and <code>gce_zone</code>:</li>
</ol>
<table>

<tr>
<th><strong>KEY</strong></th>
<th><strong>VALUE</strong></th>
<th><strong>Details</strong></th>
</tr>


<tr>
<td><code>gcp_project</code></td>
<td>&lt;your project-id&gt;</td>
<td>The Google Cloud Platform project you're using for this quickstart.</td>
</tr>
<tr>
<td><code>gcs_bucket</code></td>
<td>gs://&lt;my-bucket&gt;</td>
<td>Replace &lt;my-bucket&gt; with the name of the Cloud Storage bucket you made earlier. This bucket stores the output from the Hadoop jobs from Dataproc.</td>
</tr>
<tr>
<td><code>gce_zone</code></td>
<td><code>us-central1-a</code></td>
<td>This is the Compute Engine zone where your Cloud Dataproc cluster will be created. To chose a different zone, see <a href="https://cloud.google.com/compute/docs/regions-zones/regions-zones#available" target="_blank">Available regions &amp; zones.</a>
</td>
</tr>

</table>
<p>Click <strong>Save and Add Another</strong> after adding each variable. Your Variables table should look like this when you're finished:</p>
<p><img alt="6069c7a4f191b5a3.png" src="https://cdn.qwiklabs.com/1YBb%2F%2F98z%2Fc1FLI6JFa0AHmt1UC3ngg8cpXSZazsR%2F0%3D"></p>
<h2 id="step9">Uploading the DAG to Cloud Storage</h2>
<p>To upload the DAG:</p>
<ol>
<li>
<p>In Cloud Shell, copy and save  <a href="https://cloud.google.com/composer/docs/quickstart#defining_the_workflow">hadoop_tutorial.py</a> on your local virtual machine:</p>
</li>
</ol>
<pre><code>git clone https://github.com/GoogleCloudPlatform/python-docs-samples&#x000A;</code></pre>
<ol start="2">
<li>
<p>Change to the <code>python-docs-samples</code> directory:</p>
</li>
</ol>
<pre><code class="language-bash prettyprint">cd python-docs-samples/composer/workflows&#x000A;</code></pre>
<ol start="3">
<li>
<p>Now upload a copy of the <code>hadoop_tutorial.py</code> file to the Cloud Storage bucket, which gets automatically created when you create the environment. You can check that by going to <strong>Composer</strong> &gt; <strong>Environments</strong>. Click on the environment you created earlier, this will get you to the description of the environment you created. Find <code>DAGs folder</code>, copy the value to replace <code>DAGs_folder_path</code> in the following command to upload the file :</p>
</li>
</ol>
<pre><code>gsutil cp hadoop_tutorial.py &lt;DAGs_folder_path&gt;&#x000A;</code></pre>
<p>Cloud Composer adds the DAG to Airflow and schedules the DAG automatically. DAG changes occur within 3-5 minutes. The workflow will now be referred to as <code>composer-sample-quickstart</code>.</p>
<p>You will be able to see the task status in the Airflow web interface.</p>
<p>Click <strong>Check my progress</strong> to verify the objective.</p>
<ql-activity-tracking step="3">
    Uploading the DAG to Cloud Storage.
</ql-activity-tracking>
<h3>Exploring DAG runs</h3>
<p>When you upload your DAG file to the <code>dags</code> folder in Cloud Storage, Cloud Composer parses the file. If no errors are found, the name of the workflow appears in the DAG listing, and the workflow is queued to run immediately.</p>
<p>Make sure that you're on the DAGs tab in the Airflow web interface. It takes several minutes for this process to complete. Refresh your browser to make sure you're looking at the latest information.</p>
<p><img alt="DAGs.png" src="https://cdn.qwiklabs.com/5ScJbZzzZS9RTeCEjeA7WpXP27uKB4nLIqOpA%2FTUbQ8%3D"></p>
<ol>
<li>In Airflow, click <strong>composer_hadoop_tutorial</strong> to open the DAG details page. This page includes a graphical representation of the workflow tasks and dependencies.</li>
</ol>
<p><img alt="composer_hadoop_tutorial.png" src="https://cdn.qwiklabs.com/ewB46wniNFlyzbNJ4g8KLpwLerLOLFLKOA%2F%2BviJ18B0%3D"></p>
<ol start="2">
<li>In the toolbar, click <strong>Graph View</strong>. Mouseover the graphic for each task to see its status. Note that the border around each task also indicates the status (green border = running; red = failed, etc.).</li>
</ol>
<p><img alt="hover.png" src="https://cdn.qwiklabs.com/Mxn8A3ri4BbdbZbplhkStohV4XQnKjWZCZZuWd5vY3o%3D"></p>
<ol start="3">
<li>Click the "Refresh" link to make sure you're looking at the most recent information. The boarders of the processes change colors as the state of the process changes.</li>
</ol>
<p>Once your process reaches the Success state,  run the workflow again from the <strong>Graph View</strong>:</p>
<ol>
<li>Click the <strong>create_dataproc_cluster</strong> graphic.</li>
<li>Click <strong>Clear</strong> to reset the three tasks.
<img alt="create_cluster.png" src="https://cdn.qwiklabs.com/jyyg4%2FFy6tvMgiRabIQn4gTBx4YbyGJ7ZXIWPJpedUk%3D">
</li>
<li>Then click <strong>OK</strong> to confirm.</li>
</ol>
<p>Notice that the color around <strong>create_dataproc_cluster</strong> has changed and the state is "running".</p>
<p>You can also monitor the process in the GCP Console.</p>
<ol>
<li>
<p>Once the status for <strong>create_dataproc_cluster</strong> has changed to "running", go to  <strong>Navigation menu</strong> &gt; <strong>Dataproc</strong>, then click on:</p>
</li>
</ol>
<ul>
<li>
<p><strong>Clusters</strong> to monitor cluster creation and deletion. The cluster created by the workflow is ephemeral: it only exists for the duration of the workflow and is deleted as part of the last workflow task.</p>
</li>
<li>
<p><strong>Jobs</strong> to monitor the Apache Hadoop wordcount job. Click the Job ID to see job log output.</p>
</li>
</ul>
<ol start="2">
<li>Once Dataproc gets to a state of "Running", return to Airflow and click <strong>Refresh</strong> to see that the cluster is complete.</li>
</ol>
<p>When the <code>run_dataproc_hadoop</code> process is complete, go to <strong>Navigation menu</strong> &gt; <strong>Storage</strong> &gt; <strong>Browser</strong> and click on the name of your bucket to see the results of the wordcount in the <code>wordcount</code> folder.</p>
<h2 id="step10">Congratulations!</h2>
<p>You've successfully run a Cloud Composer workflow!</p>
<h2 id="step11">Next steps</h2>
<ul>
<li>Check out when Cloud Composer was presented at NEXT 18 in San Francisco:  <a href="https://www.youtube.com/watch?v=GeNFEtt-D4k">https://www.youtube.com/watch?v=GeNFEtt-D4k</a>
</li>
<li>To see the value of a variable, run the Airflow CLI sub-command  <a href="https://airflow.apache.org/cli.html#variables">variables</a> with the get argument or use the  <a href="https://cloud.google.com/composer/docs/quickstart#variables-ui">Airflow web interface</a>.</li>
<li>For information about the Airflow web interface, see  <a href="https://cloud.google.com/composer/docs/how-to/accessing/airflow-web-interface#accessing_the_web_interface">Accessing the web interface</a>.</li>
</ul>
<h2 id="step12">End your lab</h2>
<p>When you have completed your lab, click <strong>End Lab</strong>. Qwiklabs removes the resources you’ve used and cleans the account for you.</p>
<p>You will be given an opportunity to rate the lab experience. Select the applicable number of stars, type a comment, and then click <strong>Submit</strong>.</p>
<p>The number of stars indicates the following:</p>
<ul>
<li>1 star = Very dissatisfied</li>
<li>2 stars = Dissatisfied</li>
<li>3 stars = Neutral</li>
<li>4 stars = Satisfied</li>
<li>5 stars = Very satisfied</li>
</ul>
<p>You can close the dialog box if you don't want to provide feedback.</p>
<p>For feedback, suggestions, or corrections, please use the <strong>Support</strong> tab.</p>

<p>©2019 Google LLC All rights reserved. Google and the Google logo are trademarks of Google LLC. All other company and product names may be trademarks of the respective companies with which they are associated.</p>



</div>
<div class='js-lab-content-outline lab-content__outline'>
<a href='#step1'>Overview</a><a href='#step2'>Setup and requirements</a><a href='#step3'>Create Cloud Composer environment</a><a href='#step4'>Airflow and core concepts</a><a href='#step5'>Defining the workflow</a><a href='#step6'>Viewing environment information</a><a href='#step7'>Using the Airflow UI</a><a href='#step8'>Setting Airflow variables</a><a href='#step9'>Uploading the DAG to Cloud Storage</a><a href='#step10'>Congratulations!</a><a href='#step11'>Next steps</a><a href='#step12'>End your lab</a>
</div>
</div>

</div>


</div>
</div>
<div class='lab-assessment__tab js-lab-assessment-tab'>
<h5 class='small-label'>
Score
</h5>
<h3 class='js-lab-assessment-total-score'>
&mdash;/15
</h3>
<iframe class='l-ie-iframe-fix'></iframe>
</div>
<div class='lab-assessment__panel js-lab-assessment-panel'>
<!-- / If lab_instance has is started and assessment is generated, use -->
<!-- / lab_instance.assessment, otherwise use lab.assessment_manual -->
<div class='lab-assessment__step'>
<p class='lab-assessment__step__title'>
Create Cloud Composer environment
</p>
<p class='button button--assessment js-show-run-step-button' step_no='1'>
Run Step
</p>
<p class='lab-assessment__step__score'>
<span class='js-assessment-step-score-1'>
</span>
/ 5
</p>
</div>

<div class='lab-assessment__step'>
<p class='lab-assessment__step__title'>
Create a Cloud Storage bucket
</p>
<p class='button button--assessment js-show-run-step-button' step_no='2'>
Run Step
</p>
<p class='lab-assessment__step__score'>
<span class='js-assessment-step-score-2'>
</span>
/ 5
</p>
</div>

<div class='lab-assessment__step'>
<p class='lab-assessment__step__title'>
Uploading the DAG to Cloud Storage
</p>
<p class='button button--assessment js-show-run-step-button' step_no='3'>
Run Step
</p>
<p class='lab-assessment__step__score'>
<span class='js-assessment-step-score-3'>
</span>
/ 5
</p>
</div>

<iframe class='l-ie-iframe-fix'></iframe>
</div>
<div class='lab-introduction js-lab-introduction is-hidden'>
<div class='lab-introduction__inner'>
<h1 class='headline-1'>Welcome to Your First Lab!</h1>
<ql-icon-button class='js-skip-button'>close</ql-icon-button>
<div class='lab-introduction__video'>
<iframe allow='autoplay; encrypted-media' allowfullscreen frameborder='0' id='lab-introduction' src='https://www.youtube.com/embed/yF7EDXKTmoQ?enablejsapi=1&amp;rel=0&amp;showinfo=0'></iframe>
</div>
<a class='js-skip-button button button--outline'>Skip this video</a>
</div>
</div>



</div>
</main>
<div class='modal fade' id='lab-details-modal'>
<div class='modal-container'>
<div class='mdl-shadow--24dp modal-content'>
<div class='modal-body'>
<p class='l-mbm'>
In this lab, you create a Cloud Composer environment using the GCP Console. You then use the Airflow web interface to run a workflow that verifies a data file, creates and runs an Apache Hadoop wordcount job on a Dataproc cluster, and deletes the cluster.
</p>
<p class='small-label l-mbs'>
<strong>
Duration:
</strong>
0m setup
&middot;
90m access
&middot;
90m completion
</p>
<p class='small-label l-mbs'>
<span><strong>Levels: </strong>introductory</span>
</p>
<p class='small-label'>
<strong>
Permalink:
</strong>
<a href="https://googlecoursera.qwiklabs.com/catalog_lab/2179">https://googlecoursera.qwiklabs.com/catalog_lab/2179</a>
</p>
</div>
<div class='modal-actions'>
<a class='mdl-button mdl-button--primary mdl-js-button mdl-js-ripple-effect' data-dismiss='modal'>
Got It
</a>
</div>


</div>
</div>
<iframe class='l-ie-iframe-fix'></iframe>
</div>
<div class='modal fade' id='lab-review-modal'>
<div class='modal-container'>
<div class='mdl-shadow--24dp modal-content'>
<form class="simple_form js-lab-review-form" id="edit_lab_review_5030193" action="/lab_reviews/5030193" accept-charset="UTF-8" data-remote="true" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="_method" value="patch" /><div class='modal-body'>
<p class='label'>
How satisfied are you with this lab?*
</p>
<div class='rateit js-rateit' data-rateit-max='5' data-rateit-min='0' data-rateit-resetable='false' data-rateit-step='1' data-rateit-value='5'></div>
<div class='l-mtm'>

<div class="control-group hidden lab_review_user_id"><div class="controls"><input class="hidden" type="hidden" value="2485272" name="lab_review[user_id]" id="lab_review_user_id" /></div></div>
<div class="control-group hidden lab_review_classroom_id"><div class="controls"><input class="hidden" type="hidden" value="5956" name="lab_review[classroom_id]" id="lab_review_classroom_id" /></div></div>
<div class="control-group hidden lab_review_lab_id"><div class="controls"><input class="hidden" type="hidden" value="2179" name="lab_review[lab_id]" id="lab_review_lab_id" /></div></div>
<div class="control-group hidden lab_review_focus_id"><div class="controls"><input class="hidden" type="hidden" value="46741" name="lab_review[focus_id]" id="lab_review_focus_id" /></div></div>
<div class="control-group hidden lab_review_rating"><div class="controls"><input class="hidden js-rating-input" type="hidden" value="2" name="lab_review[rating]" id="lab_review_rating" /></div></div>
<div class="control-group text optional lab_review_comment"><label class="text optional control-label" for="lab_review_comment">Comment</label><div class="controls"><textarea class="text optional" name="lab_review[comment]" id="lab_review_comment">
</textarea></div></div>
</div>
</div>
<div class='modal-actions'>
<a class='mdl-button mdl-button--primary mdl-js-button mdl-js-ripple-effect' data-dismiss='modal'>
Cancel
</a>
<input type="submit" name="commit" value="Submit" disabled="disabled" class="btn mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--primary" id="submit" data-disabled="false" data-disable-with="Submit" />
</div>
</form>

</div>
</div>
<iframe class='l-ie-iframe-fix'></iframe>
</div>

<script>
  $( function() {
    ql.initMaterialInputs();
    initChosen();
    initSearch();
    initTabs();
    ql.list.init();
    ql.favoriting.init();
    ql.header.myAccount.init();
    initTooltips();
    ql.autocomplete.init();
    ql.modals.init();
    ql.toggleButtons.init();
    ql.analytics.init();
    initLabContent( );
  ql.labOutline.links.init();
  ql.labOutline.layout.init();
  initLabReviewModal();
  ql.labAssessment.init();
  ql.labIntroduction.init( true );
  ql.labData.init();
  initLabTranslations( {"are_you_sure":"All done? If you end this lab, you will lose all your work. You may not be able to restart the lab if there is a quota limit. Are you sure you want to end this lab?\n","in_progress":"*In Progress*","ending":"*Ending*","starting":"*Starting, please wait*","end_concurrent_labs":"Sorry, you can only run one lab at a time. To start this lab, please confirm that you want all of your existing labs to end.\n","copied":"Copied","no_resource":"Error retrieving resource.","no_support":"No Support","mac_press":"Press ⌘-C to copy","thanks_review":"Thanks for reviewing this lab.","windows_press":"Press Ctrl-C to copy","days":"days"} );
  ql.labRun.init();
  ql.initHeader();
  ql.navigation.init();
  ql.navPanel.init();
  ql.navigation.init();
  
  });
</script>
<style>
  .mdl-layout__container {
    position: static
  }
</style>
</body>
</html>
